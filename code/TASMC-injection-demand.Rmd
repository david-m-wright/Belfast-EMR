---
title: "BIRAX study - injection demand model validation"
author: "David M Wright - d.wright@qub.ac.uk"
date: "Document compiled: `r Sys.Date()`"
output: 
  bookdown::html_document2:
     toc: true
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(rprojroot)
library(tidyverse)
library(janitor)
```

`r R.version.string`   

```{r run-analysis, include=FALSE}
source(find_rstudio_root_file("Code/TASMC-injection-demand.R"))
source(find_rstudio_root_file("Code/TASMC-injection-demand-years-SL.R"))
source(find_rstudio_root_file("Code/TASMC-visual-acuity-years-SL.R"))
```

# Introduction

This analysis is of Electronic Medical Records (EMR) from the Tel Aviv Sourasky Medical Centre (TASMC) extracted over the period `r min(mdc$Date)` to `r max(mdc$Date)`. The aim of the study is to investigate the potential for machine learning to identify factors and biomarkers associated with long-term AMD treatment response.

This analysis investigates the extent to which the number of anti-VEGF injections received by each eye and visual acuity following treatment can be predicted based on measurements of retinal fluid produced by the Notal Ophthalmic Analyzer (NOA) at baseline and at six months. Models for these outcomes were trained using data from the Belfast Health and Social Care Trust. This is an external validation using the TASMC data.

The following outcomes were investigated:

1. The number of injections received by an eye in each of the first three years of treatment.   
2. Visual acuity at the end of each year of treatment.    

Cohort construction is described in 'TASMC-cohort-construction.html` (`r nrow(eye_demand_raw)` eyes from `r nrow(distinct(eye_demand_raw, PatientID))` patients).

* Excluded `r nrow(filter(eye_demand_raw, exclude_6months_fluid))` eyes without a fluid measurement at 6 months (+-2 months, Figure \@ref(fig:close-to-snapshot)).    

A total of `r nrow(eye_demand)` eyes from `r nrow(distinct(eye_demand, PatientID))` patients remained after these exclusions.

```{r close-to-snapshot, fig.cap="Distribution of actual times since baseline for the 'Six month' fluid measurement."}
fluid_6months_imp_demand %>%
  select(PatientID, EyeCode) %>%
  inner_join(
    fluid_history_imp %>%
      filter(snapshot, follow_up_month == 6)
    ,
    by = c("PatientID", "EyeCode")
  ) %>%
  ggplot(aes(x = months_since_index)) +
  geom_histogram(bins = 25, fill = "white", colour= "black") +
  theme_light() +
  labs(x = "Months since baseline",
       y = "Count")
```

## Patient characteristics

```{r descriptives}
eye_demand %>%
   transmute(Age = index_age, Gender, Eyes = " ") %>%
  GenerateDescriptives(type = c(Age = "Mean (Range)")) %>%
  kbl(caption = "Baseline characteristics of eyes with AMD. Frequency and percentage reported for categorical variables.") %>%
  kable_paper()
```

```{r follow-up-length}
bind_rows(
  eye_demand %>%
    inner_join(injections_yr, by = c("PatientID", "EyeCode")) %>%
    transmute(Injections = three_yr_injections,
              `Total injections` = three_yr_injections) %>%
    GenerateDescriptives(type = c(
      Injections = "Median (IQR)",
      `Total injections` = " "
    )),
  
  GenerateDescriptives(transmute(va_history_demand, `Total VA exams` = " ")),
  
  va_history_demand %>%
    group_by(PatientID, EyeCode) %>%
    summarise(
      `VA exams` = n(),
      `VA years observed` = max(months_since_index / 12),
      .groups = "drop"
    ) %>%
    select(-PatientID,-EyeCode) %>%
    GenerateDescriptives(
      type = c(`VA exams` = "Median (Range)",
               `VA years observed` = "Median (Range)")
    ),
  
  GenerateDescriptives(
    transmute(fluid_history_demand, `Total OCT fluid measurements` = " ")
  ),
  
  fluid_history_demand %>%
    group_by(PatientID, EyeCode) %>%
    summarise(
      `OCT fluid measurements` = n(),
      `OCT fluid years observed` = max(months_since_index / 12),
      .groups = "drop"
    ) %>%
    select(-PatientID,-EyeCode) %>%
    GenerateDescriptives(
      type = c(
        `OCT fluid measurements` = "Median (Range)",
        `OCT fluid years observed` = "Median (Range)"
      )
    )
) %>%
  kbl(caption = "Number of injections and examinations in first three years of treatment.") %>%
  kable_paper()
```


## Visual acuity

```{r va-baseline}
va_history_demand %>% 
  filter(baseline) %>% 
  transmute(va_logmar, va_category_snellen, Eyes = "n") %>% 
  GenerateDescriptives(type = c(va_logmar = "Median (Range)")) %>% 
  left_join(var_desc, by = "Variable") %>%
  mutate(Description = coalesce(Description, Variable)) %>%
  select(Description, everything(), -Variable) %>%
  kbl(caption = "Distribution of visual acuity outcomes at baseline.") %>% 
  kable_paper()
```

```{r va-baseline-amd-type}
fluid_history_demand %>% 
  filter(baseline) %>% 
  select(PatientID, EyeCode, amd_type) %>% 
  inner_join(
va_history_demand %>% 
  filter(baseline),
by = c("PatientID", "EyeCode")) %>% 
  transmute(amd_type, va_logmar, va_category_snellen, Eyes = "n") %>% 
  GenerateDescriptives(col_var = amd_type, type = c(va_logmar = "Median (Range)")) %>% 
  left_join(var_desc, by = "Variable") %>%
  mutate(Description = coalesce(Description, Variable)) %>%
  select(Description, everything(), -Variable) %>%
  kbl(caption = "Distribution of visual acuity outcomes at baseline by fluid presence.") %>% 
  kable_paper()
```


# Machine learning pipeline

An ensemble machine learning pipeline was used to find the best prediction for each eye, using a diverse set of learners to capture interactions and non-linear relationships among variables in the absence of a-priori information on the correct functional form.
The fluid measurements are listed in Table \@ref(tab:noa-selected) and prior to model fitting, each variable was standardised and missing measurements were imputed with zero. Baseline and six month measurements for each variable were used 

```{r noa-selected}
enframe(noa_volumes_selected, value = "Variable", name = NULL) %>% 
  left_join(noa_dictionary, by = c("Variable" = "Raw Parameter")) %>% 
  kbl(caption = "Retinal fluid measurements included in models predicting injection demand.") %>% 
  kable_paper()
```

# Injections by treatment year

Discrimination of all three models was moderate (Table \@ref(tab:demand-yr-performance))). The correlation between the predicted and observed number of injections was low to moderate. Overall performance in terms of mean absolute deviation was poor but better in year 1 than in years 2 and 3. Arouund 40% of predictions were within two injections of the number received (Tables \@ref(tab:demand-yr-deviations) and \@ref(tab:demand-yr-abs-deviations)).

```{r demand-yr-performance}
sl_preds_yrs_6 %>% 
  group_by(outcome) %>% 
  group_modify(~summarise_sl_fit(.), .keep = TRUE) %>% 
  kbl(caption = "Prediction characteristics of fitted models by year.", digits = 2) %>% 
  kable_paper()
```

```{r demand-yr-deviations}
sl_preds_yrs_6 %>% 
  tabyl(deviation, outcome) %>% 
  adorn_percentages("col") %>% 
  adorn_pct_formatting() %>% 
  adorn_ns() %>% 
  kbl(caption = "Deviation between number of injections predicted and number of injections received by treatment year model.") %>% 
  kable_paper()
```

```{r demand-yr-abs-deviations}
sl_preds_yrs_6 %>% 
  count(outcome, abs_deviation) %>% 
  group_by(outcome) %>% 
  mutate(cumulative = cumsum(n)/sum(n)) %>% 
  pivot_wider(names_from = outcome, values_from = c(n, cumulative), values_fill = 0) %>% 
   adorn_pct_formatting(... = matches("cumulative_in")) %>% 
   adorn_percentages(denominator = "col", ... = matches("^n_in")) %>%
  adorn_pct_formatting(... = matches("^n_in")) %>% 
    adorn_ns(... = matches("^n_in")) %>%
    kbl(caption = "Absolute deviation between number of injections predicted and number of injections received by treatment year model.") %>% 
  kable_paper()
```

Across the full range of predictions and for each year, the model tended to under-predict the number of injections required (i.e. there were more injections given in TASMC than were expected based on the the BHSCT training data, Figure \@ref(fig:calibration-yr-6)). Eyes received a greater number of injections in year one than in subsequent years.

```{r calibration-yr-6, fig.width = 7, fig.height = 9, fig.cap="Predicted number of injections vs. number of injections received by treatment year. Solid lines indicates calibration slopes (blue = fitted, black = perfect).", warning=FALSE, message =FALSE}
sl_preds_yrs_6 %>% 
  ggplot(aes(y = Y, x = pred_Y)) +
  geom_jitter(width = 0.3) +
  geom_abline(aes(intercept = 0, slope =1)) +
  geom_smooth(method = lm) +
   scale_x_continuous(breaks = function(lims){seq(0, round(lims[2]), by=5)}, minor_breaks = function(lims){seq(0, round(lims[2]), by=1)}, limits = c(0, NA)) +
   scale_y_continuous(breaks = function(lims){seq(0, round(lims[2]), by=5)}, minor_breaks = function(lims){seq(0, round(lims[2]), by=1)}, limits = c(0, NA)) +
  theme_light() +
  labs(x = "Injections (predicted)",
       y = "Injections (received)") +
  facet_wrap(~outcome, ncol=1)
```

# Visual acuity by treatment year

Discrimination of all three models was moderate (Table \@ref(tab:va-yr-performance))). The correlation between the predicted and observed number of injections was moderate. Overall performance in terms of mean absolute deviation was moderate, with mean deviations ~ 0.4 on the logMAR scale, corresponding to three to four lines on the chart. There was a negative skew in the deviations for each year (Figure \@ref(fig:va-yr-deviations)), indicating that the majority of eyes had better visual acuity than predicted. The majority of predictions were within 0.3 on the logMAR scale (three lines) of the observed visual acuity measurements for years 1 and 2 (Table \@ref(tab:va-abs-deviations)). 

```{r va-yr-performance}
sl_preds_va_yrs_6 %>% 
  group_by(outcome) %>% 
  group_modify(~summarise_sl_fit(.), .keep = TRUE) %>% 
  kbl(caption = "Prediction characteristics of fitted models by year.", digits = 2) %>% 
  kable_paper()
```

```{r va-yr-deviations, fig.cap = "Deviations between predicted and observed visual acuity measures by treatment year."}
sl_preds_va_yrs_6 %>% 
  ggplot(aes(x = deviation)) +
  geom_histogram(fill= "white", colour = "black", bins = 30) +
  scale_x_continuous(minor_breaks = seq(-1, 1, 0.1)) +
  theme_light() +
  facet_wrap(~outcome, ncol = 1)
```

```{r va-abs-deviations}
sl_preds_va_yrs_6 %>% 
mutate(absolute_deviation = cut(abs_deviation, breaks =  seq(0, 1.5, 0.1))) %>% 
  count(outcome, absolute_deviation) %>% 
  group_by(outcome) %>% 
  mutate(cumulative = cumsum(n)/sum(n)) %>% 
  pivot_wider(names_from = outcome, values_from = c(n, cumulative), values_fill = 0) %>% 
   adorn_pct_formatting(... = matches("cumulative_va")) %>% 
   adorn_percentages(denominator = "col", ... = matches("^n_va")) %>%
  adorn_pct_formatting(... = matches("^n_va")) %>% 
    adorn_ns(... = matches("^n_va")) %>%
    kbl(caption = "Absolute deviation between predicted and observed visual acuity by treatment year model.") %>% 
  kable_paper()
```

The same pattern towards over-prediction at the lower end of the response curve and under-prediction at the upper end was observed for each year, but was less evident in year one (Figure \@ref(fig:calibration-va-yrs-6)). Translating from the logMAR scale this indicates that those predicted to have good visual acuity were likely to outperform the prediction, whereas those predicted to have poor visual acuity were likely to have worse vision than predicted.

```{r calibration-va-yrs-6, fig.cap="Predicted vs. observed visual acuity at the end of each treatment year. Solid lines indicates calibration slopes (blue = fitted, black = perfect).", fig.width = 7, fig.height = 9, message=FALSE, warning=FALSE}
sl_preds_va_yrs_6 %>% 
  ggplot(aes(y = Y, x = pred_Y)) +
  geom_point() +
  geom_abline(aes(intercept = 0, slope =1)) +
    geom_smooth(method = lm) +
  theme_light() +
  # scale_x_log10() +
  # scale_y_log10() +
  scale_x_continuous( minor_breaks = function(lims){seq(0, lims[2], by=0.1)}, limits = c(0, NA)) +
  scale_y_continuous( minor_breaks = function(lims){seq(0, lims[2], by=0.1)}, limits = c(0, NA)) +
  labs(x = "VA at end of treatment year (predicted)",
       y = "VA at end of treatment year (observed)") +
  facet_wrap(~outcome, ncol = 1)
```

